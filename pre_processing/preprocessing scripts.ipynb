{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library stuff\n",
    "# Install\n",
    "#!pip install mne\n",
    "#!pip install pandas\n",
    "#!pip install numpy\n",
    "\n",
    "# Importing libraries\n",
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mne import Epochs, pick_types\n",
    "from mne.preprocessing import ICA\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "from mne.channels import make_standard_montage\n",
    "from mne.decoding import UnsupervisedSpatialFilter\n",
    "from mne.viz import plot_topomap\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import pytz\n",
    "from mne.decoding import UnsupervisedSpatialFilter\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=23, n_times=723402\n",
      "    Range : 0 ... 723401 =      0.000 ...  2836.867 secs\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AarPi\\AppData\\Local\\Temp\\ipykernel_22308\\1027169809.py:68: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,19,23,33,37,44,50,61,62,227,286,290,322,333,350,354,366,376,385,402,411,428,445,455,466,501,508,516,517) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  psychopy_df = pd.read_csv(file_path, delimiter=',', skiprows=0, header=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.1 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.10\n",
      "- Lower transition bandwidth: 0.10 Hz (-6 dB cutoff frequency: 0.05 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 8415 samples (33.000 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 59 - 61 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 59.35\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 59.10 Hz)\n",
      "- Upper passband edge: 60.65 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 60.90 Hz)\n",
      "- Filter length: 1683 samples (6.600 s)\n",
      "\n",
      "Fitting ICA to data using 8 channels (please be patient, this may take a while)\n",
      "Selecting by number: 8 components\n",
      "Fitting ICA took 6.0s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (8 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 8 PCA components\n",
      "Used Annotations descriptions: [np.str_('certainly_learned'), np.str_('not_learned')]\n",
      "Not setting metadata\n",
      "173 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 173 events and 307 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "158 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 158 events and 307 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 307 original time points ...\n",
      "0 bad epochs dropped\n",
      "Creating RawArray with float64 data, n_channels=23, n_times=749956\n",
      "    Range : 0 ... 749955 =      0.000 ...  2941.000 secs\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AarPi\\AppData\\Local\\Temp\\ipykernel_22308\\1027169809.py:68: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,19,31,40,46,57,58,223,282,316,329,346,360,376,393,403,416,433,443,454,488,495,503,504) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  psychopy_df = pd.read_csv(file_path, delimiter=',', skiprows=0, header=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.1 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.10\n",
      "- Lower transition bandwidth: 0.10 Hz (-6 dB cutoff frequency: 0.05 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 8415 samples (33.000 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 59 - 61 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 59.35\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 59.10 Hz)\n",
      "- Upper passband edge: 60.65 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 60.90 Hz)\n",
      "- Filter length: 1683 samples (6.600 s)\n",
      "\n",
      "Fitting ICA to data using 8 channels (please be patient, this may take a while)\n",
      "Selecting by number: 8 components\n",
      "Fitting ICA took 5.3s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (8 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 8 PCA components\n",
      "Used Annotations descriptions: [np.str_('certainly_learned'), np.str_('not_learned')]\n",
      "Not setting metadata\n",
      "162 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 162 events and 307 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "141 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 141 events and 307 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 21 events and 307 original time points ...\n",
      "0 bad epochs dropped\n",
      "Creating RawArray with float64 data, n_channels=23, n_times=761851\n",
      "    Range : 0 ... 761850 =      0.000 ...  2987.647 secs\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AarPi\\AppData\\Local\\Temp\\ipykernel_22308\\1027169809.py:68: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,19,31,40,46,57,58,223,282,316,327,344,358,374,391,401,415,432,442,453,488,495,503,504) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  psychopy_df = pd.read_csv(file_path, delimiter=',', skiprows=0, header=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.1 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.10\n",
      "- Lower transition bandwidth: 0.10 Hz (-6 dB cutoff frequency: 0.05 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 8415 samples (33.000 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 59 - 61 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 59.35\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 59.10 Hz)\n",
      "- Upper passband edge: 60.65 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 60.90 Hz)\n",
      "- Filter length: 1683 samples (6.600 s)\n",
      "\n",
      "Fitting ICA to data using 8 channels (please be patient, this may take a while)\n",
      "Selecting by number: 8 components\n",
      "Fitting ICA took 2.6s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (8 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 8 PCA components\n",
      "Used Annotations descriptions: [np.str_('certainly_learned'), np.str_('not_learned')]\n",
      "Not setting metadata\n",
      "157 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 157 events and 307 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "143 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 143 events and 307 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 14 events and 307 original time points ...\n",
      "0 bad epochs dropped\n",
      "Creating RawArray with float64 data, n_channels=23, n_times=736192\n",
      "    Range : 0 ... 736191 =      0.000 ...  2887.024 secs\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AarPi\\AppData\\Local\\Temp\\ipykernel_22308\\1027169809.py:68: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,19,31,40,46,57,58,223,282,316,327,344,358,374,391,401,415,432,442,453,487,494,502,503) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  psychopy_df = pd.read_csv(file_path, delimiter=',', skiprows=0, header=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.1 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.10\n",
      "- Lower transition bandwidth: 0.10 Hz (-6 dB cutoff frequency: 0.05 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 8415 samples (33.000 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 59 - 61 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 59.35\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 59.10 Hz)\n",
      "- Upper passband edge: 60.65 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 60.90 Hz)\n",
      "- Filter length: 1683 samples (6.600 s)\n",
      "\n",
      "Fitting ICA to data using 8 channels (please be patient, this may take a while)\n",
      "Selecting by number: 8 components\n",
      "Fitting ICA took 9.2s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (8 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 8 PCA components\n",
      "Used Annotations descriptions: [np.str_('certainly_learned'), np.str_('not_learned')]\n",
      "Not setting metadata\n",
      "118 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 118 events and 307 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "103 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 103 events and 307 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 307 original time points ...\n",
      "0 bad epochs dropped\n",
      "Creating RawArray with float64 data, n_channels=23, n_times=688988\n",
      "    Range : 0 ... 688987 =      0.000 ...  2701.910 secs\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AarPi\\AppData\\Local\\Temp\\ipykernel_22308\\1027169809.py:68: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,19,31,40,42,48,50,63,64,229,288,322,333,350,364,380,397,399,409,420,437,439,449,462,498,505,513,514) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  psychopy_df = pd.read_csv(file_path, delimiter=',', skiprows=0, header=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.1 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.10\n",
      "- Lower transition bandwidth: 0.10 Hz (-6 dB cutoff frequency: 0.05 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 8415 samples (33.000 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 59 - 61 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 59.35\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 59.10 Hz)\n",
      "- Upper passband edge: 60.65 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 60.90 Hz)\n",
      "- Filter length: 1683 samples (6.600 s)\n",
      "\n",
      "Fitting ICA to data using 8 channels (please be patient, this may take a while)\n",
      "Selecting by number: 8 components\n",
      "Fitting ICA took 4.0s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (8 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 8 PCA components\n",
      "Used Annotations descriptions: [np.str_('certainly_learned'), np.str_('not_learned')]\n",
      "Not setting metadata\n",
      "135 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 135 events and 307 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "65 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 65 events and 307 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "70 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 70 events and 307 original time points ...\n",
      "0 bad epochs dropped\n",
      "Creating RawArray with float64 data, n_channels=23, n_times=801742\n",
      "    Range : 0 ... 801741 =      0.000 ...  3144.082 secs\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AarPi\\AppData\\Local\\Temp\\ipykernel_22308\\1027169809.py:68: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,19,31,40,46,57,58,223,282,314,325,342,355,371,388,397,413,430,439,453,487,494,502,503,513) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  psychopy_df = pd.read_csv(file_path, delimiter=',', skiprows=0, header=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.1 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.10\n",
      "- Lower transition bandwidth: 0.10 Hz (-6 dB cutoff frequency: 0.05 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 8415 samples (33.000 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 59 - 61 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 59.35\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 59.10 Hz)\n",
      "- Upper passband edge: 60.65 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 60.90 Hz)\n",
      "- Filter length: 1683 samples (6.600 s)\n",
      "\n",
      "Fitting ICA to data using 8 channels (please be patient, this may take a while)\n",
      "Selecting by number: 8 components\n",
      "Fitting ICA took 6.7s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (8 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 8 PCA components\n",
      "Used Annotations descriptions: [np.str_('certainly_learned'), np.str_('not_learned')]\n",
      "Not setting metadata\n",
      "140 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 140 events and 307 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "135 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 135 events and 307 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "5 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 5 events and 307 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "def preprocessing(path_EEG_CSV, path_PsychoPy_log, path_PsychoPy_CSV, participantName):\n",
    "\t\n",
    "\t# Helper functions to convert from UNIX time to UTC time\n",
    "\t# UNIX time is saved as an integer (seconds since 1/1/1970)\n",
    "\t# UTC time is saved as a string (\"YYYY-MM-DDTHH:MM:SSZ\")\n",
    "\tdef unix_to_utc(unix_timestamp):\n",
    "\t\tutc_time = datetime.fromtimestamp(unix_timestamp, timezone.utc)\n",
    "\t\tlocal_timezone = pytz.timezone('America/Los_Angeles')\n",
    "\t\tlocal_time = utc_time.astimezone(local_timezone) # This gives our UTC time converted to PST\n",
    "\t\treturn utc_time # This gives our raw UTC time\n",
    "\tdef utc_to_unix(utc_time_str):\n",
    "\t\tutc_time = datetime.strptime(utc_time_str, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\t\tutc_time = utc_time.replace(tzinfo=timezone.utc)\n",
    "\t\tunix_timestamp = int(utc_time.timestamp())\n",
    "\t\treturn unix_timestamp\n",
    "\t\n",
    "\t# Function to load the data. Simply enter a file path\n",
    "\tdef load_eeg_data(file_path):\n",
    "\n",
    "\t\t# Create a dataframe from our data, replace NAs with 0s\n",
    "\t\tdf = pd.read_csv(file_path, sep='\\t', skiprows=2, header=None)\n",
    "\t\tdf.fillna(0.0, inplace=True)\n",
    "\n",
    "\t\t# Extract EEG data\n",
    "\t\ttrial_data = df.iloc[:, 1:24].values\n",
    "\n",
    "\t\t# Declares channel names and types of each set of data\n",
    "\t\tsfreq = 255  # sample rate in Hz\n",
    "\t\tch_names = ['Channel {}'.format(i+1) for i in range(trial_data.shape[1])]\n",
    "\t\tch_types = ['eeg' for i in range(trial_data.shape[1])]\n",
    "\n",
    "\t\t# Get the measurement date\n",
    "\t\tstart_time_unix = trial_data[0][21] # This is where EEG start time is stored in UNIX time\n",
    "\t\tmeas_date = unix_to_utc(start_time_unix) # However, MNE takes UTC time\n",
    "\n",
    "\t\t# Create info structures and RawArray objects for each set of data\n",
    "\t\tinfo = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "\t\tinfo.set_meas_date(meas_date)\n",
    "\t\traw = mne.io.RawArray(trial_data.T, info)\n",
    "\n",
    "\t\t# Removing irrelevant channels\n",
    "\t\tch_names = [raw.ch_names]\n",
    "\t\tch_names_to_keep = [ch_names[0][0:8]]\n",
    "\t\traw = raw.pick(ch_names_to_keep[0])\n",
    "\n",
    "\t\t# Return the RawArray object\n",
    "\t\treturn raw\n",
    "\t\n",
    "\t# Helper function, converts PsychoPy's timestamp into UNIX\n",
    "\tdef psychopy_to_unix(psychopy_time):\n",
    "\t\t\n",
    "\t\t# Define the format of the input timestamp\n",
    "\t\tformat_string = \"%Y-%m-%d %Hh%M.%S.%f %z\"\n",
    "\n",
    "\t\t# Parse the custom timestamp into a datetime object\n",
    "\t\tparsed_timestamp = datetime.strptime(psychopy_time, format_string)\n",
    "\n",
    "\t\t# Convert the datetime object to a Unix timestamp (floating-point for microseconds)\n",
    "\t\tunix_timestamp = parsed_timestamp.timestamp()\n",
    "\n",
    "\t\t# Print the Unix timestamp\n",
    "\t\treturn unix_timestamp\n",
    "\n",
    "\t# Function to load psychopy data. Simply input the file path\n",
    "\tdef load_psychopy_data(file_path):\n",
    "\n",
    "\t\t# Read psychopy data into a pandas dataframe\n",
    "\t\tpsychopy_df = pd.read_csv(file_path, delimiter=',', skiprows=0, header=0)\n",
    "\t\t\n",
    "\t\t#create a new column for the unix time of psychopy stimuli\n",
    "\t\tpsychopy_df = psychopy_df.dropna(subset=[\"expStart\"])\n",
    "\t\tpsychopy_df[\"expStart\"] = psychopy_df[\"expStart\"].astype(str)\n",
    "\t\tpsychopy_df[\"unix_time\"] = psychopy_df[\"expStart\"].apply(psychopy_to_unix)\n",
    "\t\t\n",
    "\t\treturn psychopy_df\n",
    "\t\n",
    "\t# Function to load log data\n",
    "\tdef load_log_data(file_path):\n",
    "\t\tlog_df = pd.read_csv(file_path, sep=\"\\t\", header=None, encoding=\"utf-8\")\n",
    "\t\tlog_df = log_df.rename(columns={0: \"time\", 1: \"type\", 2: \"action\"}) # Renames columns for easier access\n",
    "\t\treturn log_df\n",
    "\t\n",
    "\taction_practice_training = [\"practice_amharicc: autoDraw = True\",\n",
    "\t\t\t\t\t\t\t\"amharic_practice2: autoDraw = True\"]\n",
    "\taction_practice_testing = [\"textAmharic_9: autoDraw = True\"]\n",
    "\taction_correctness = [\"textCheck: text = '✓'\", \n",
    "\t\t\t\t\t\t\"textXmark: text = '✗'\"]\n",
    "\taction_training = [\"amharics1: autoDraw = True\", \n",
    "\t\t\t\t\t\t\"amharics1_2: autoDraw = True\", \n",
    "\t\t\t\t\t\t\"amharics2: autoDraw = True\", \n",
    "\t\t\t\t\t\t\"amharics2_2: autoDraw = True\", \n",
    "\t\t\t\t\t\t\"amharics3: autoDraw = True\", \n",
    "\t\t\t\t\t\t\"amharics3_2: autoDraw = True\", \n",
    "\t\t\t\t\t\t\"amharics4: autoDraw = True\", \n",
    "\t\t\t\t\t\t\"amharics4_2\"]\n",
    "\taction_testing = [\"textAmharic_5: autoDraw = True\", \n",
    "\t\t\t\t\t\"textAmharic_6: autoDraw = True\", \n",
    "\t\t\t\t\t\"textAmharic_7: autoDraw = True\", \n",
    "\t\t\t\t\t\"textAmharic_8: autoDraw = True\"]\n",
    "\taction_english = [\"textOptionA_5: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionB_5: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionC_5: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionD_5: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionA_6: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionB_6: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionC_6: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionD_6: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionA_7: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionB_7: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionC_7: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionD_7: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionA_8: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionB_8: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionC_8: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionD_8: autoDraw = True\"]\n",
    "\taction_keypress = [\"Keypress: left\",\n",
    "\t\t\t\t\t\"Keypress: right\",\n",
    "\t\t\t\t\t\"Keypress: up\",\n",
    "\t\t\t\t\t\"Keypress: down\",\n",
    "\t\t\t\t\t\"Keypress: space\"]\n",
    "\taction_diamond = [\"textDiamond_8: autoDraw = True\", \n",
    "\t\t\t\t\t\"textDiamond_3: autoDraw = True\", \n",
    "\t\t\t\t\t\"textDiamond_5: autoDraw = True\",\n",
    "\t\t\t\t\t\"textDiamond_6: autoDraw = True\",\n",
    "\t\t\t\t\t\"textDiamond_7: autoDraw = True\",]\n",
    "\n",
    "\traw = load_eeg_data(path_EEG_CSV)\n",
    "\tpsychopy_df = load_psychopy_data(path_PsychoPy_CSV)\n",
    "\tlog_df = load_log_data(path_PsychoPy_log)\n",
    "\n",
    "\tfiltered_actions = action_testing + action_correctness\n",
    "\tpattern = \"|\".join(filtered_actions)\n",
    "\tsub_df = log_df[log_df[\"action\"].str.contains(pattern, na=False, regex=True)]\n",
    "\tsub_df.index = range(len(sub_df)) # Renaming row indices for easier iteration\n",
    "\n",
    "\tfiltered_certainty = action_keypress + action_diamond + action_practice_testing + action_testing + action_correctness\n",
    "\tcertainty_pattern = \"|\".join(filtered_certainty)\n",
    "\tcertainty_df = log_df[log_df[\"action\"].str.contains(certainty_pattern, na=False, regex=True)]\n",
    "\tcertainty_df.index = range(len(certainty_df)) # Renaming row indices for easier iteration\n",
    "\n",
    "\tcertainty_timestamps = []\n",
    "\tfor index in range(len(certainty_df)): # Certainty timestamps\n",
    "\t\tif (\"textAmharic\" in certainty_df[\"action\"][index]): \n",
    "\t\t\tcertainty = float(certainty_df[\"time\"][index+2] - certainty_df[\"time\"][index+1])\n",
    "\t\t\tif certainty < 0.5:\n",
    "\t\t\t\ttimestamp, correctness = float(certainty_df[\"time\"][index]), certainty_df[\"action\"][index+3][-2]\n",
    "\t\t\t\tcertainty_timestamps.append((timestamp, correctness))\n",
    "\t\t\n",
    "\tdef extract_rows(df, check_symbol, pattern):\n",
    "\t\t\"\"\"\n",
    "\t\tExtract rows where the 'action' contains 'textAmharic' and the next row's 'action'\n",
    "\t\tcontains the specified check symbol.\n",
    "\t\t\n",
    "\t\tParameters:\n",
    "\t\t\tdf (pd.DataFrame): The DataFrame containing the data.\n",
    "\t\t\tcheck_symbol (str): The symbol to look for in the next row's action.\n",
    "\t\t\t\n",
    "\t\tReturns:\n",
    "\t\t\tlearned_list (list): List of rows (as pd.Series) that meet the criteria.\n",
    "\t\t\"\"\"\n",
    "\t\tlist = []\n",
    "\t\tcheck_symbol_exists = (check_symbol != \"\")\n",
    "\t\t\n",
    "\t\t# Loop through all rows\n",
    "\t\tfor i in range(len(df)):\n",
    "\t\t\tcurrent_action = df.iloc[i][\"action\"]\n",
    "\t\t\tif (check_symbol_exists) and (i < len(df) - 1):\n",
    "\t\t\t\tnext_action = df.iloc[i + 1][\"action\"]\n",
    "\t\t\t\tif str(pattern) in current_action and check_symbol in next_action:\n",
    "\t\t\t\t\tlist.append(df.iloc[i][\"time\"])\n",
    "\t\t\telse:\n",
    "\t\t\t\tif str(pattern) in current_action:\n",
    "\t\t\t\t\tlist.append(df.iloc[i][\"time\"])\n",
    "\t\treturn list\n",
    "\n",
    "\n",
    "\tlearned_list = extract_rows(sub_df, check_symbol=\"✓\", pattern=\"textAmharic\")\n",
    "\tnot_learned_list = extract_rows(sub_df, check_symbol=\"✗\", pattern=\"textAmharic\")\n",
    "\n",
    "\t# lists are a bunch of np.float64, convert these all to standard floats\n",
    "\tdef np_float_to_float(np_float64_list):\n",
    "\t\tnew_list = []\n",
    "\n",
    "\t\tfor i in range(0,len(np_float64_list)):\n",
    "\t\t\tnew_list.append(float(np_float64_list[i]))\n",
    "\t\t\n",
    "\t\treturn new_list\n",
    "\n",
    "\n",
    "\t# now we have lists of just the times\n",
    "\tlearned_list_times = np_float_to_float(learned_list)\n",
    "\tnot_learned_list_times = np_float_to_float(not_learned_list)\n",
    "\t#english_list_times = np_float_to_float(english_list)\n",
    "\tcertainty_list_times = []\n",
    "\tfor timestamp, correctness in certainty_timestamps:\n",
    "\t\tif (correctness == \"✓\"): \n",
    "\t\t\tcertainty_list_times.append(timestamp)\n",
    "\n",
    "\tduration = 1\n",
    "\tlength = len(certainty_list_times) + len(not_learned_list_times) \n",
    "\tduration_list = [duration] * length\n",
    "\tnot_learned_tags = [\"not_learned\"] * len(not_learned_list_times)\n",
    "\tcertainty_tags = [\"certainly_learned\"] * len(certainty_list_times)\n",
    "\tfinal_onsets = certainty_list_times + not_learned_list_times\n",
    "\tfinal_description = certainty_tags + not_learned_tags\n",
    "\n",
    "\tbuffer = psychopy_df.loc[0, 'unix_time'] - utc_to_unix(raw.info['meas_date'].strftime(\"%Y-%m-%dT%H:%M:%SZ\"))\n",
    "\tnew_orig_time = (raw.info['meas_date'] + timedelta(seconds=buffer)).strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "\n",
    "\tlater_annot = mne.Annotations(\n",
    "\t\tonset = final_onsets,\n",
    "\t\tduration = duration_list,\n",
    "\t\tdescription = final_description,\n",
    "\t\torig_time=new_orig_time,\n",
    "\t)\n",
    "\n",
    "\traw = raw.copy().set_annotations(later_annot)\n",
    "\t#raw.compute_psd(fmin=0,fmax=50).plot()\n",
    "\tf_low = 0.1\n",
    "\tf_high = 30\n",
    "\tdata_cleaned = raw.filter(f_low, f_high, fir_design=\"firwin\", skip_by_annotation=\"edge\")   \n",
    "\t#low and high pass filter, fir_design can be changed to match what lit review did\n",
    "\n",
    "\t#notch filter for electrical noise\n",
    "\tdata_cleaned.notch_filter(60)\n",
    "\tpicks = pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False, exclude=\"bads\")  \n",
    "\n",
    "\tica = ICA(n_components=8, random_state=97, method=\"fastica\")\n",
    "\n",
    "\tica.fit(raw)   \n",
    "\t#raw cleaned has been through filtering\n",
    "\t#clean will have gone through ica\n",
    "\n",
    "\tdata_cleaned = ica.apply(raw)\n",
    "\n",
    "\t# Extract events from annotations\n",
    "\tevents, event_id = mne.events_from_annotations(data_cleaned)\n",
    "\n",
    "\t# Define the epoch time window (start and end in seconds relative to event onset)\n",
    "\ttmin, tmax = -0.2, 1  # for example, 200ms before and 500ms after each event\n",
    "\n",
    "\t#mne expects event ID to be ints and not strings, so we need to change our annotations via dictionary\n",
    "\n",
    "\t# Create epochs\n",
    "\tevent_epochs = mne.Epochs(\n",
    "\t\tdata_cleaned,                # Variable that contains our data\n",
    "\t\tevents,                      # Events we want to investigate, remember we changed T1 and T2 to this\n",
    "\t\tevent_id={\"certainly_learned\": 1, \"not_learned\": 2},\n",
    "\t\ttmin=tmin,                   # Start time relative to event, creating a buffer of how many seconds around event we want\n",
    "\t\ttmax=tmax,                   # End time relative to event\n",
    "\t\tproj=True,                   # Re-references data after everything we've done so far\n",
    "\t\tpicks=picks,                 # Only use channels specified in 'picks' (AKA EEG)\n",
    "\t\tbaseline=None,               # No baseline correction\n",
    "\t\tpreload=True                 # Load the epochs into memory for faster access\n",
    "\t)\n",
    "\n",
    "\t# make different epochs for each label\n",
    "\tcertainly_learned_event_epochs = mne.Epochs(\n",
    "\t\tdata_cleaned,                # Variable that contains our data\n",
    "\t\tevents,                      # Events we want to investigate, remember we changed T1 and T2 to this\n",
    "\t\tevent_id={\"certainly_learned\": 1},\n",
    "\t\ttmin=tmin,                   # Start time relative to event, creating a buffer of how many seconds around event we want\n",
    "\t\ttmax=tmax,                   # End time relative to event\n",
    "\t\tproj=True,                   # Re-references data after everything we've done so far\n",
    "\t\tpicks=picks,                 # Only use channels specified in 'picks' (AKA EEG)\n",
    "\t\tbaseline=None,               # No baseline correction\n",
    "\t\tpreload=True                 # Load the epochs into memory for faster access\n",
    "\t)\n",
    "\n",
    "\tnot_learned_event_epochs = mne.Epochs(\n",
    "\t\tdata_cleaned,                # Variable that contains our data\n",
    "\t\tevents,                      # Events we want to investigate, remember we changed T1 and T2 to this\n",
    "\t\tevent_id={\"not_learned\": 2},\n",
    "\t\ttmin=tmin,                   # Start time relative to event, creating a buffer of how many seconds around event we want\n",
    "\t\ttmax=tmax,                   # End time relative to event\n",
    "\t\tproj=True,                   # Re-references data after everything we've done so far\n",
    "\t\tpicks=picks,                 # Only use channels specified in 'picks' (AKA EEG)\n",
    "\t\tbaseline=None,               # No baseline correction\n",
    "\t\tpreload=True                 # Load the epochs into memory for faster access\n",
    "\t)\n",
    "\n",
    "\n",
    "\t# VISUALIZATION\n",
    "\t# evoked_dict = {event: event_epochs[event].average() for event in event_id}\n",
    "\t# certainly_evoked = certainly_learned_event_epochs.average()\n",
    "\t# not_learned_evoked = not_learned_event_epochs.average()\n",
    "\t# evoked_dict = {\"certainly_learned\": certainly_evoked, \"not_learned\": not_learned_evoked}\n",
    "\t# mne.viz.plot_compare_evokeds(evoked_dict, picks='eeg', title='ERP Comparison')\n",
    "\n",
    "\n",
    "\n",
    "\t# Step 1: Get epoch data\n",
    "\tX_epochs = event_epochs.get_data()\n",
    "\t#print(f\"Original shape: {X_epochs.shape}\")  # Shape: (epochs, channels, times) times is the amount of samples. \n",
    "\n",
    "\t# repeat for the other epochs\n",
    "\tcertainly_learned_epochs = certainly_learned_event_epochs.get_data()\n",
    "\t#print(f\"Original shape: {certainly_learned_epochs.shape}\")\n",
    "\t#learned_epochs = learned_event_epochs.get_data()\n",
    "\t#print(f\"Original shape: {learned_epochs.shape}\")\n",
    "\n",
    "\tnot_learned_epochs = not_learned_event_epochs.get_data()\n",
    "\t#(f\"Original shape: {not_learned_epochs.shape}\")\n",
    "\t# Step 2: Apply PCA\n",
    "\tn_components = 8\n",
    "\tpca_mne = UnsupervisedSpatialFilter(PCA(n_components=n_components), average=False)\n",
    "\tX_pca = pca_mne.fit_transform(X_epochs)\n",
    "\t#print(f\"After PCA shape: {X_pca.shape}\")  # Shape: (epochs, components, times)\n",
    "\n",
    "\t# repeat\n",
    "\tcertainly_learned_pca = pca_mne.fit_transform(certainly_learned_epochs)\n",
    "\t#print(f\"After PCA shape: {certainly_learned_pca.shape}\")\n",
    "\n",
    "\t#learned_pca = pca_mne.fit_transform(learned_epochs)\n",
    "\t#print(f\"After PCA shape: {learned_pca.shape}\")\n",
    "\n",
    "\tnot_learned_pca = pca_mne.fit_transform(not_learned_epochs)\n",
    "\t#print(f\"After PCA shape: {not_learned_pca.shape}\")\n",
    "\t# Step 3: Reshape data for machine learning\n",
    "\tX_flat = X_pca.reshape(X_pca.shape[0], -1)  # Shape: (epochs, components * times)\n",
    "\t#print(f\"Flattened shape: {X_flat.shape}\")\n",
    "\t#print(X_flat)\n",
    "\n",
    "\tcertainly_learned_flat = certainly_learned_pca.reshape(certainly_learned_pca.shape[0], -1)  # Shape: (epochs, components * times)\n",
    "\t#print(f\"Flattened shape: {certainly_learned_flat.shape}\")\n",
    "\t#print(certainly_learned_flat)\n",
    "\n",
    "\t#learned_flat = learned_pca.reshape(learned_pca.shape[0], -1)  # Shape: (epochs, components * times)\n",
    "\t#print(f\"Flattened shape: {learned_flat.shape}\")\n",
    "\t#print(learned_flat)\n",
    "\n",
    "\tnot_learned_flat = not_learned_pca.reshape(not_learned_pca.shape[0], -1)  # Shape: (epochs, components * times)\n",
    "\t#print(f\"Flattened shape: {not_learned_flat.shape}\")\n",
    "\t#print(not_learned_flat)\n",
    "\n",
    "\t# write to a csv\n",
    "\tnp.savetxt('../processed_EEG_data/' + participantName + '.csv',X_flat, delimiter=',', fmt='%f')\n",
    "\tnp.savetxt('../clean_learned_EEG/clean_learned_' + participantName + '.csv', certainly_learned_flat, delimiter=',', fmt='%f')\n",
    "\tnp.savetxt('../clean_not_learned_EEG/clean_notLearned_' + participantName + '.csv',not_learned_flat, delimiter=',', fmt='%f')\n",
    "\n",
    "# Store our EEG data path in a variable\n",
    "\n",
    "# Aaron's relative file paths\n",
    "\n",
    "# Josh Irby\n",
    "irby_eeg_file_path_csv = '../../../Neurotech 24-25/EEG_data_new/EEG-20250317T232255Z-001/EEG/3_9_2025_JoshIrby_OpenBCI/OpenBCISession_2025-03-09_14-39-02/BrainFlow-RAW_2025-03-09_14-39-02_0.csv'\n",
    "irby_psyhcopy_file_path_csv = '../../../Neurotech 24-25/psychoPy_data_new/PsychoPy-20250317T232226Z-001/PsychoPy/3_9_2025_JoshIrby_PsychoPy/6_finaltest_2025-03-09_14h42.58.498.csv'\n",
    "irby_log_path = '../../../Neurotech 24-25/psychoPy_data_new/PsychoPy-20250317T232226Z-001/PsychoPy/3_9_2025_JoshIrby_PsychoPy/6_finaltest_2025-03-09_14h42.58.498.log'\n",
    "\n",
    "# Sarah\n",
    "sarah_eeg_file_path_csv = '../../../Neurotech 24-25/EEG_data_new/EEG-20250317T232255Z-001/EEG/3_9_2025_Sarah_OpenBCI/OpenBCISession_2025-03-09_13-24-49/BrainFlow-RAW_2025-03-09_13-24-49_0.csv'\n",
    "sarah_psyhcopy_file_path_csv ='../../../Neurotech 24-25/psychoPy_data_new/PsychoPy-20250317T232226Z-001/PsychoPy/3_9_2025_Sarah_PsychoPy/138512_finaltest_2025-03-09_13h31.15.766.csv'\n",
    "sarah_log_path = '../../../Neurotech 24-25/psychoPy_data_new/PsychoPy-20250317T232226Z-001/PsychoPy/3_9_2025_Sarah_PsychoPy/138512_finaltest_2025-03-09_13h31.15.766.log'\n",
    "\n",
    "# Devin\n",
    "devin_eeg_file_path_csv = '../../../Neurotech 24-25/EEG_data_new/EEG-20250317T232255Z-001/EEG/3_11_2025_Devin_OpenBCI/OpenBCISession_2025-03-11_17-07-21/BrainFlow-RAW_2025-03-11_17-07-21_1.csv'\n",
    "devin_psyhcopy_file_path_csv = '../../../Neurotech 24-25/psychoPy_data_new/PsychoPy-20250317T232226Z-001/PsychoPy/3_11_2025_Devin_PsychoPy/devin_finaltest_2025-03-11_17h30.44.028.csv'\n",
    "devin_log_path = '../../../Neurotech 24-25/psychoPy_data_new/PsychoPy-20250317T232226Z-001/PsychoPy/3_11_2025_Devin_PsychoPy/devin_finaltest_2025-03-11_17h30.44.028.log'\n",
    "\n",
    "# Chengyi\n",
    "chengyi_eeg_file_path_csv = '../../../Neurotech 24-25/EEG_data_new/EEG-20250317T232255Z-001/EEG/3_12_2025_Chengyi_OpenBCI/OpenBCISession_2025-03-12_17-07-49/BrainFlow-RAW_2025-03-12_17-07-49_1.csv'\n",
    "chengyi_psyhcopy_file_path_csv = '../../../Neurotech 24-25/psychoPy_data_new/PsychoPy-20250317T232226Z-001/PsychoPy/3_12_2025_Chengyi_PsychoPy/69_finaltest_2025-03-12_17h33.18.370.csv'\n",
    "chengyi_log_path = '../../../Neurotech 24-25/psychoPy_data_new/PsychoPy-20250317T232226Z-001/PsychoPy/3_12_2025_Chengyi_PsychoPy/69_finaltest_2025-03-12_17h33.18.370.log'\n",
    "\n",
    "# Afnaan\n",
    "afnaan_eeg_file_path_csv = '../../../Neurotech 24-25/EEG_data_new/EEG-20250317T232255Z-001/EEG/3_13_2025_Afnaan_OpenBCI/OpenBCISession_2025-03-13_22-03-16/BrainFlow-RAW_2025-03-13_22-03-16_0.csv'\n",
    "afnaan_psyhcopy_file_path_csv = '../../../Neurotech 24-25/psychoPy_data_new/PsychoPy-20250317T232226Z-001/PsychoPy/3_13_2025_Afnaan_PsychoPy/69000_finaltest_2025-03-13_22h43.00.897.csv'\n",
    "afnaan_log_path = '../../../Neurotech 24-25/psychoPy_data_new/PsychoPy-20250317T232226Z-001/PsychoPy/3_13_2025_Afnaan_PsychoPy/69000_finaltest_2025-03-13_22h43.00.897.log'\n",
    "\n",
    "# Joshua Wei\n",
    "wei_eeg_file_path_csv = '../../../Neurotech 24-25/EEG_data_new/EEG-20250317T232255Z-001/EEG/3_13_2025_JoshuaWei_OpenBCI/OpenBCISession_2025-03-13_19-40-36/BrainFlow-RAW_2025-03-13_19-40-36_0.csv'\n",
    "wei_psyhcopy_file_path_csv = '../../../Neurotech 24-25/psychoPy_data_new/PsychoPy-20250317T232226Z-001/PsychoPy/3_13_2025_JoshuaWei_PsychoPy/42069_finaltest_2025-03-13_20h02.28.660.csv'\n",
    "wei_log_path = '../../../Neurotech 24-25/psychoPy_data_new/PsychoPy-20250317T232226Z-001/PsychoPy/3_13_2025_JoshuaWei_PsychoPy/42069_finaltest_2025-03-13_20h02.28.660.log'\n",
    "\n",
    "\n",
    "# Chengyi's files\n",
    "# eeg_file_path_csv = 'C:/Users/cheng/OneDrive/Desktop/Data Collection (OpenBCI & PsychoPy)-20250404T031700Z-001/Data Collection (OpenBCI & PsychoPy)/EEG/3_13_2025_JoshuaWei_OpenBCI/OpenBCISession_2025-03-13_19-40-36/BrainFlow-RAW_2025-03-13_19-40-36_0.csv'\n",
    "# psyhcopy_file_path_csv = 'C:/Users/cheng/OneDrive/Desktop/Data Collection (OpenBCI & PsychoPy)-20250404T031700Z-001/Data Collection (OpenBCI & PsychoPy)\\PsychoPy/3_13_2025_JoshuaWei_PsychoPy/42069_finaltest_2025-03-13_20h02.28.660.csv'\n",
    "# log_path = 'C:/Users/cheng/OneDrive/Desktop/Data Collection (OpenBCI & PsychoPy)-20250404T031700Z-001/Data Collection (OpenBCI & PsychoPy)/PsychoPy/3_13_2025_JoshuaWei_PsychoPy/42069_finaltest_2025-03-13_20h02.28.660.log'\n",
    "\n",
    "\n",
    "# writing them seperately for now to isolate any bad files\n",
    "preprocessing(wei_eeg_file_path_csv, wei_log_path, wei_psyhcopy_file_path_csv, \"JoshuaWei\")\n",
    "preprocessing(irby_eeg_file_path_csv, irby_log_path, irby_psyhcopy_file_path_csv, \"Irby\")\n",
    "preprocessing(sarah_eeg_file_path_csv, sarah_log_path, sarah_psyhcopy_file_path_csv, \"Sarah\")\n",
    "preprocessing(devin_eeg_file_path_csv, devin_log_path, devin_psyhcopy_file_path_csv, \"Devin\")\n",
    "preprocessing(chengyi_eeg_file_path_csv, chengyi_log_path, chengyi_psyhcopy_file_path_csv, \"Chengyi\")\n",
    "preprocessing(afnaan_eeg_file_path_csv, afnaan_log_path, afnaan_psyhcopy_file_path_csv, \"Afnaan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv combiner\n",
    "# create one csv for not learned and one for learned\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def combine_csv_files(directory, output_filename):\n",
    "    \"\"\"Combines all CSV files in a directory into a single CSV file.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the directory containing the CSV files.\n",
    "        output_filename (str, optional): Name of the output CSV file. Defaults to \"combined.csv\".\n",
    "    \"\"\"\n",
    "    all_filenames = glob.glob(os.path.join(directory, \"*.csv\"))\n",
    "    all_df = []\n",
    "    for f in all_filenames:\n",
    "        df = pd.read_csv(f)\n",
    "        all_df.append(df)\n",
    "    \n",
    "    combined_df = pd.concat(all_df, ignore_index=True)\n",
    "    file_path = os.path.join(directory, output_filename)\n",
    "    combined_df.to_csv(file_path, index=False)\n",
    "\n",
    "# combine the clean ones:\n",
    "directory_path_learned = \"../clean_learned_EEG\"\n",
    "directory_path_notLearned = \"../clean_not_learned_EEG\"\n",
    "combine_csv_files(directory_path_learned, output_filename=\"combined_learned.csv\")\n",
    "combine_csv_files(directory_path_notLearned, output_filename=\"combined_notLearned.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/cheng/OneDrive/Desktop/NeuroLingo/Data Collection (OpenBCI & PsychoPy)-20250404T031700Z-001/Data Collection (OpenBCI & PsychoPy)/EEG/3_9_2025_JoshIrby_OpenBCI/OpenBCISession_2025-03-09_14-39-02/BrainFlow-RAW_2025-03-09_14-39-02_0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 356\u001b[0m\n\u001b[0;32m    354\u001b[0m not_learned_evoked_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m participant \u001b[38;5;129;01min\u001b[39;00m participants:\n\u001b[1;32m--> 356\u001b[0m \tcertainly_learned_event_epochs, not_learned_event_epochs \u001b[38;5;241m=\u001b[39m \u001b[43mERP_Graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparticipant\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meeg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparticipant\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpsychopy_log\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparticipant\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpsychopy_csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparticipant\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m    357\u001b[0m \tcertainly_evoked_list\u001b[38;5;241m.\u001b[39mappend(certainly_learned_event_epochs\u001b[38;5;241m.\u001b[39maverage())\n\u001b[0;32m    358\u001b[0m \tnot_learned_evoked_list\u001b[38;5;241m.\u001b[39mappend(not_learned_event_epochs\u001b[38;5;241m.\u001b[39maverage())\n",
      "Cell \u001b[1;32mIn[3], line 154\u001b[0m, in \u001b[0;36mERP_Graph\u001b[1;34m(path_EEG_CSV, path_PsychoPy_log, path_PsychoPy_CSV, participantName)\u001b[0m\n\u001b[0;32m    143\u001b[0m action_keypress \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeypress: left\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    144\u001b[0m \t\t\t\t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeypress: right\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    145\u001b[0m \t\t\t\t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeypress: up\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    146\u001b[0m \t\t\t\t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeypress: down\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    147\u001b[0m \t\t\t\t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeypress: space\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    148\u001b[0m action_diamond \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtextDiamond_8: autoDraw = True\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m    149\u001b[0m \t\t\t\t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtextDiamond_3: autoDraw = True\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m    150\u001b[0m \t\t\t\t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtextDiamond_5: autoDraw = True\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    151\u001b[0m \t\t\t\t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtextDiamond_6: autoDraw = True\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    152\u001b[0m \t\t\t\t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtextDiamond_7: autoDraw = True\u001b[39m\u001b[38;5;124m\"\u001b[39m,]\n\u001b[1;32m--> 154\u001b[0m raw \u001b[38;5;241m=\u001b[39m \u001b[43mload_eeg_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_EEG_CSV\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m psychopy_df \u001b[38;5;241m=\u001b[39m load_psychopy_data(path_PsychoPy_CSV)\n\u001b[0;32m    156\u001b[0m log_df \u001b[38;5;241m=\u001b[39m load_log_data(path_PsychoPy_log)\n",
      "Cell \u001b[1;32mIn[3], line 42\u001b[0m, in \u001b[0;36mERP_Graph.<locals>.load_eeg_data\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_eeg_data\u001b[39m(file_path):\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \t\u001b[38;5;66;03m# Create a dataframe from our data, replace NAs with 0s\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \tdf \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \tdf\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0.0\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     45\u001b[0m \t\u001b[38;5;66;03m# Extract EEG data\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/cheng/OneDrive/Desktop/NeuroLingo/Data Collection (OpenBCI & PsychoPy)-20250404T031700Z-001/Data Collection (OpenBCI & PsychoPy)/EEG/3_9_2025_JoshIrby_OpenBCI/OpenBCISession_2025-03-09_14-39-02/BrainFlow-RAW_2025-03-09_14-39-02_0.csv'"
     ]
    }
   ],
   "source": [
    "# Install\n",
    "#!pip install mne\n",
    "#!pip install pandas\n",
    "#!pip install numpy\n",
    "\n",
    "# Import libraries\n",
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mne import Epochs, pick_types\n",
    "from mne.preprocessing import ICA\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "from mne.channels import make_standard_montage\n",
    "from mne.decoding import UnsupervisedSpatialFilter\n",
    "from mne.viz import plot_topomap\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import pytz\n",
    "from mne.decoding import UnsupervisedSpatialFilter\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def ERP_Graph(path_EEG_CSV, path_PsychoPy_log, path_PsychoPy_CSV, participantName):\n",
    "\t\n",
    "\t# Helper functions to convert from UNIX time to UTC time\n",
    "\t# UNIX time is saved as an integer (seconds since 1/1/1970)\n",
    "\t# UTC time is saved as a string (\"YYYY-MM-DDTHH:MM:SSZ\")\n",
    "\tdef unix_to_utc(unix_timestamp):\n",
    "\t\tutc_time = datetime.fromtimestamp(unix_timestamp, timezone.utc)\n",
    "\t\tlocal_timezone = pytz.timezone('America/Los_Angeles')\n",
    "\t\tlocal_time = utc_time.astimezone(local_timezone) # This gives our UTC time converted to PST\n",
    "\t\treturn utc_time # This gives our raw UTC time\n",
    "\tdef utc_to_unix(utc_time_str):\n",
    "\t\tutc_time = datetime.strptime(utc_time_str, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\t\tutc_time = utc_time.replace(tzinfo=timezone.utc)\n",
    "\t\tunix_timestamp = int(utc_time.timestamp())\n",
    "\t\treturn unix_timestamp\n",
    "\t\n",
    "\t# Function to load the data. Simply enter a file path\n",
    "\tdef load_eeg_data(file_path):\n",
    "\n",
    "\t\t# Create a dataframe from our data, replace NAs with 0s\n",
    "\t\tdf = pd.read_csv(file_path, sep='\\t', skiprows=2, header=None)\n",
    "\t\tdf.fillna(0.0, inplace=True)\n",
    "\n",
    "\t\t# Extract EEG data\n",
    "\t\ttrial_data = df.iloc[:, 1:24].values\n",
    "\n",
    "\t\t# Declares channel names and types of each set of data\n",
    "\t\tsfreq = 255  # sample rate in Hz\n",
    "\t\tch_names = ['Channel {}'.format(i+1) for i in range(trial_data.shape[1])]\n",
    "\t\tch_types = ['eeg' for i in range(trial_data.shape[1])]\n",
    "\n",
    "\t\t# Get the measurement date\n",
    "\t\tstart_time_unix = trial_data[0][21] # This is where EEG start time is stored in UNIX time\n",
    "\t\tmeas_date = unix_to_utc(start_time_unix) # However, MNE takes UTC time\n",
    "\n",
    "\t\t# Create info structures and RawArray objects for each set of data\n",
    "\t\tinfo = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "\t\tinfo.set_meas_date(meas_date)\n",
    "\t\traw = mne.io.RawArray(trial_data.T, info)\n",
    "\n",
    "\t\t# Removing irrelevant channels\n",
    "\t\tch_names = [raw.ch_names]\n",
    "\t\tch_names_to_keep = [ch_names[0][0:8]]\n",
    "\t\traw = raw.pick(ch_names_to_keep[0])\n",
    "\n",
    "\t\t# Now you can work with the MNE Raw object\n",
    "\t\t# print(raw.info)\n",
    "\t\t# raw.plot(scalings='auto')\n",
    "\t\t# raw.__len__()\n",
    "\t\t# More attributes here: https://mne.tools/1.8/generated/mne.io.RawArray.html\n",
    "\n",
    "\t\t# Return the RawArray object\n",
    "\t\treturn raw\n",
    "\t\n",
    "\t# Helper function, converts PsychoPy's timestamp into UNIX\n",
    "\tdef psychopy_to_unix(psychopy_time):\n",
    "\t\t\n",
    "\t\t# Define the format of the input timestamp\n",
    "\t\tformat_string = \"%Y-%m-%d %Hh%M.%S.%f %z\"\n",
    "\n",
    "\t\t# Parse the custom timestamp into a datetime object\n",
    "\t\tparsed_timestamp = datetime.strptime(psychopy_time, format_string)\n",
    "\n",
    "\t\t# Convert the datetime object to a Unix timestamp (floating-point for microseconds)\n",
    "\t\tunix_timestamp = parsed_timestamp.timestamp()\n",
    "\n",
    "\t\t# Print the Unix timestamp\n",
    "\t\treturn unix_timestamp\n",
    "\n",
    "\t# Function to load psychopy data. Simply input the file path\n",
    "\tdef load_psychopy_data(file_path):\n",
    "\n",
    "\t\t# Read psychopy data into a pandas dataframe\n",
    "\t\tpsychopy_df = pd.read_csv(file_path, delimiter=',', skiprows=0, header=0)\n",
    "\t\t\n",
    "\t\t#create a new column for the unix time of psychopy stimuli\n",
    "\t\tpsychopy_df = psychopy_df.dropna(subset=[\"expStart\"])\n",
    "\t\tpsychopy_df[\"expStart\"] = psychopy_df[\"expStart\"].astype(str)\n",
    "\t\tpsychopy_df[\"unix_time\"] = psychopy_df[\"expStart\"].apply(psychopy_to_unix)\n",
    "\t\t\n",
    "\t\treturn psychopy_df\n",
    "\t\n",
    "\t# Function to load log data\n",
    "\tdef load_log_data(file_path):\n",
    "\t\tlog_df = pd.read_csv(file_path, sep=\"\\t\", header=None, encoding=\"utf-8\")\n",
    "\t\tlog_df = log_df.rename(columns={0: \"time\", 1: \"type\", 2: \"action\"}) # Renames columns for easier access\n",
    "\t\treturn log_df\n",
    "\t\n",
    "\taction_practice_training = [\"practice_amharicc: autoDraw = True\",\n",
    "\t\t\t\t\t\t\t\"amharic_practice2: autoDraw = True\"]\n",
    "\taction_practice_testing = [\"textAmharic_9: autoDraw = True\"]\n",
    "\taction_correctness = [\"textCheck: text = '✓'\", \n",
    "\t\t\t\t\t\t\"textXmark: text = '✗'\"]\n",
    "\taction_training = [\"amharics1: autoDraw = True\", \n",
    "\t\t\t\t\t\t\"amharics1_2: autoDraw = True\", \n",
    "\t\t\t\t\t\t\"amharics2: autoDraw = True\", \n",
    "\t\t\t\t\t\t\"amharics2_2: autoDraw = True\", \n",
    "\t\t\t\t\t\t\"amharics3: autoDraw = True\", \n",
    "\t\t\t\t\t\t\"amharics3_2: autoDraw = True\", \n",
    "\t\t\t\t\t\t\"amharics4: autoDraw = True\", \n",
    "\t\t\t\t\t\t\"amharics4_2\"]\n",
    "\taction_testing = [\"textAmharic_5: autoDraw = True\", \n",
    "\t\t\t\t\t\"textAmharic_6: autoDraw = True\", \n",
    "\t\t\t\t\t\"textAmharic_7: autoDraw = True\", \n",
    "\t\t\t\t\t\"textAmharic_8: autoDraw = True\"]\n",
    "\taction_english = [\"textOptionA_5: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionB_5: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionC_5: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionD_5: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionA_6: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionB_6: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionC_6: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionD_6: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionA_7: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionB_7: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionC_7: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionD_7: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionA_8: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionB_8: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionC_8: autoDraw = True\",\n",
    "\t\t\t\t\t\"textOptionD_8: autoDraw = True\"]\n",
    "\taction_keypress = [\"Keypress: left\",\n",
    "\t\t\t\t\t\"Keypress: right\",\n",
    "\t\t\t\t\t\"Keypress: up\",\n",
    "\t\t\t\t\t\"Keypress: down\",\n",
    "\t\t\t\t\t\"Keypress: space\"]\n",
    "\taction_diamond = [\"textDiamond_8: autoDraw = True\", \n",
    "\t\t\t\t\t\"textDiamond_3: autoDraw = True\", \n",
    "\t\t\t\t\t\"textDiamond_5: autoDraw = True\",\n",
    "\t\t\t\t\t\"textDiamond_6: autoDraw = True\",\n",
    "\t\t\t\t\t\"textDiamond_7: autoDraw = True\",]\n",
    "\n",
    "\traw = load_eeg_data(path_EEG_CSV)\n",
    "\tpsychopy_df = load_psychopy_data(path_PsychoPy_CSV)\n",
    "\tlog_df = load_log_data(path_PsychoPy_log)\n",
    "\n",
    "\tfiltered_actions = action_testing + action_correctness\n",
    "\tpattern = \"|\".join(filtered_actions)\n",
    "\tsub_df = log_df[log_df[\"action\"].str.contains(pattern, na=False, regex=True)]\n",
    "\tsub_df.index = range(len(sub_df)) # Renaming row indices for easier iteration\n",
    "\n",
    "\tfiltered_certainty = action_keypress + action_diamond + action_practice_testing + action_testing + action_correctness\n",
    "\tcertainty_pattern = \"|\".join(filtered_certainty)\n",
    "\tcertainty_df = log_df[log_df[\"action\"].str.contains(certainty_pattern, na=False, regex=True)]\n",
    "\tcertainty_df.index = range(len(certainty_df)) # Renaming row indices for easier iteration\n",
    "\n",
    "\tcertainty_timestamps = []\n",
    "\tfor index in range(len(certainty_df)): # Certainty timestamps\n",
    "\t\tif (\"textAmharic\" in certainty_df[\"action\"][index]): \n",
    "\t\t\tcertainty = float(certainty_df[\"time\"][index+2] - certainty_df[\"time\"][index+1])\n",
    "\t\t\tif certainty < 0.5:\n",
    "\t\t\t\ttimestamp, correctness = float(certainty_df[\"time\"][index]), certainty_df[\"action\"][index+3][-2]\n",
    "\t\t\t\tcertainty_timestamps.append((timestamp, correctness))\n",
    "\t\t\n",
    "\tdef extract_rows(df, check_symbol, pattern):\n",
    "\t\t\"\"\"\n",
    "\t\tExtract rows where the 'action' contains 'textAmharic' and the next row's 'action'\n",
    "\t\tcontains the specified check symbol.\n",
    "\t\t\n",
    "\t\tParameters:\n",
    "\t\t\tdf (pd.DataFrame): The DataFrame containing the data.\n",
    "\t\t\tcheck_symbol (str): The symbol to look for in the next row's action.\n",
    "\t\t\t\n",
    "\t\tReturns:\n",
    "\t\t\tlearned_list (list): List of rows (as pd.Series) that meet the criteria.\n",
    "\t\t\"\"\"\n",
    "\t\tlist = []\n",
    "\t\tcheck_symbol_exists = (check_symbol != \"\")\n",
    "\t\t\n",
    "\t\t# Loop through all rows\n",
    "\t\tfor i in range(len(df)):\n",
    "\t\t\tcurrent_action = df.iloc[i][\"action\"]\n",
    "\t\t\tif (check_symbol_exists) and (i < len(df) - 1):\n",
    "\t\t\t\tnext_action = df.iloc[i + 1][\"action\"]\n",
    "\t\t\t\tif str(pattern) in current_action and check_symbol in next_action:\n",
    "\t\t\t\t\tlist.append(df.iloc[i][\"time\"])\n",
    "\t\t\telse:\n",
    "\t\t\t\tif str(pattern) in current_action:\n",
    "\t\t\t\t\tlist.append(df.iloc[i][\"time\"])\n",
    "\t\treturn list\n",
    "\n",
    "\n",
    "\tlearned_list = extract_rows(sub_df, check_symbol=\"✓\", pattern=\"textAmharic\")\n",
    "\tnot_learned_list = extract_rows(sub_df, check_symbol=\"✗\", pattern=\"textAmharic\")\n",
    "\n",
    "\t# lists are a bunch of np.float64, convert these all to standard floats\n",
    "\tdef np_float_to_float(np_float64_list):\n",
    "\t\tnew_list = []\n",
    "\n",
    "\t\tfor i in range(0,len(np_float64_list)):\n",
    "\t\t\tnew_list.append(float(np_float64_list[i]))\n",
    "\t\t\n",
    "\t\treturn new_list\n",
    "\n",
    "\tlearned_list_times = np_float_to_float(learned_list)\n",
    "\tnot_learned_list_times = np_float_to_float(not_learned_list)\n",
    "\tcertainty_list_times = []\n",
    "\tfor timestamp, correctness in certainty_timestamps:\n",
    "\t\tif (correctness == \"✓\"): \n",
    "\t\t\tcertainty_list_times.append(timestamp)\n",
    "\n",
    "\tduration = 1\n",
    "\tlength = len(certainty_list_times) + len(not_learned_list_times) \n",
    "\tduration_list = [duration] * length\n",
    "\tnot_learned_tags = [\"not_learned\"] * len(not_learned_list_times)\n",
    "\tcertainty_tags = [\"certainly_learned\"] * len(certainty_list_times)\n",
    "\tfinal_onsets = certainty_list_times + not_learned_list_times\n",
    "\tfinal_description = certainty_tags + not_learned_tags\n",
    "\n",
    "\tbuffer = psychopy_df.loc[0, 'unix_time'] - utc_to_unix(raw.info['meas_date'].strftime(\"%Y-%m-%dT%H:%M:%SZ\"))\n",
    "\tnew_orig_time = (raw.info['meas_date'] + timedelta(seconds=buffer)).strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "\n",
    "\tlater_annot = mne.Annotations(\n",
    "\t\tonset = final_onsets,\n",
    "\t\tduration = duration_list,\n",
    "\t\tdescription = final_description,\n",
    "\t\torig_time=new_orig_time,\n",
    "\t)\n",
    "\n",
    "\traw = raw.copy().set_annotations(later_annot)\n",
    "\t#raw.compute_psd(fmin=0,fmax=50).plot()\n",
    "\tf_low = 0.1\n",
    "\tf_high = 30\n",
    "\tdata_cleaned = raw.filter(f_low, f_high, fir_design=\"firwin\", skip_by_annotation=\"edge\")   \n",
    "\tdata_cleaned.notch_filter(60)\n",
    "\tpicks = pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False, exclude=\"bads\")  \n",
    "\tica = ICA(n_components=8, random_state=97, method=\"fastica\")\n",
    "\tica.fit(raw)   \n",
    "\n",
    "\n",
    "\tdata_cleaned = ica.apply(raw)\n",
    "\n",
    "\t# Extract events from annotations\n",
    "\tevents, event_id = mne.events_from_annotations(data_cleaned)\n",
    "\n",
    "\t# Define the epoch time window (start and end in seconds relative to event onset)\n",
    "\ttmin, tmax = -0.2, 1  # for example, 200ms before and 500ms after each event\n",
    "\n",
    "\t#mne expects event ID to be ints and not strings, so we need to change our annotations via dictionary\n",
    "\n",
    "\t# Create epochs\n",
    "\tevent_epochs = mne.Epochs(\n",
    "\t\tdata_cleaned,                # Variable that contains our data\n",
    "\t\tevents,                      # Events we want to investigate, remember we changed T1 and T2 to this\n",
    "\t\tevent_id={\"certainly_learned\": 1, \"not_learned\": 2},\n",
    "\t\ttmin=tmin,                   # Start time relative to event, creating a buffer of how many seconds around event we want\n",
    "\t\ttmax=tmax,                   # End time relative to event\n",
    "\t\tproj=True,                   # Re-references data after everything we've done so far\n",
    "\t\tpicks=picks,                 # Only use channels specified in 'picks' (AKA EEG)\n",
    "\t\tbaseline=None,               # No baseline correction\n",
    "\t\tpreload=True                 # Load the epochs into memory for faster access\n",
    "\t)\n",
    "\n",
    "\t# make different epochs for each label\n",
    "\tcertainly_learned_event_epochs = mne.Epochs(\n",
    "\t\tdata_cleaned,                # Variable that contains our data\n",
    "\t\tevents,                      # Events we want to investigate, remember we changed T1 and T2 to this\n",
    "\t\tevent_id={\"certainly_learned\": 1},\n",
    "\t\ttmin=tmin,                   # Start time relative to event, creating a buffer of how many seconds around event we want\n",
    "\t\ttmax=tmax,                   # End time relative to event\n",
    "\t\tproj=True,                   # Re-references data after everything we've done so far\n",
    "\t\tpicks=picks,                 # Only use channels specified in 'picks' (AKA EEG)\n",
    "\t\tbaseline=None,               # No baseline correction\n",
    "\t\tpreload=True                 # Load the epochs into memory for faster access\n",
    "\t)\n",
    "\n",
    "\tnot_learned_event_epochs = mne.Epochs(\n",
    "\t\tdata_cleaned,                # Variable that contains our data\n",
    "\t\tevents,                      # Events we want to investigate, remember we changed T1 and T2 to this\n",
    "\t\tevent_id={\"not_learned\": 2},\n",
    "\t\ttmin=tmin,                   # Start time relative to event, creating a buffer of how many seconds around event we want\n",
    "\t\ttmax=tmax,                   # End time relative to event\n",
    "\t\tproj=True,                   # Re-references data after everything we've done so far\n",
    "\t\tpicks=picks,                 # Only use channels specified in 'picks' (AKA EEG)\n",
    "\t\tbaseline=None,               # No baseline correction\n",
    "\t\tpreload=True                 # Load the epochs into memory for faster access\n",
    "\t)\n",
    "\n",
    "\n",
    "\t# return for VISUALIZATION\n",
    "\treturn certainly_learned_event_epochs, not_learned_event_epochs\n",
    "\n",
    "\n",
    "# Store our EEG data path in a variable\n",
    "#eeg_file_path_csv = '../../../Neurotech 24-25/EEG_data_new/EEG-20250317T232255Z-001/EEG/3_9_2025_JoshIrby_OpenBCI/OpenBCISession_2025-03-09_14-39-02/BrainFlow-RAW_2025-03-09_14-39-02_0.csv'\n",
    "#psyhcopy_file_path_csv = '../../../Neurotech 24-25/psychoPy_data_new/PsychoPy-20250317T232226Z-001/PsychoPy/3_9_2025_JoshIrby_PsychoPy/6_finaltest_2025-03-09_14h42.58.498.csv'\n",
    "#log_path = '../../../Neurotech 24-25/psychoPy_data_new/PsychoPy-20250317T232226Z-001/PsychoPy/3_9_2025_JoshIrby_PsychoPy/6_finaltest_2025-03-09_14h42.58.498.log'\n",
    "\n",
    "JoshuaIrby = {\n",
    "\t\"name\": \"JoshuaIrby\",\n",
    "    \"eeg\": \"C:/Users/cheng/OneDrive/Desktop/NeuroLingo/Data Collection (OpenBCI & PsychoPy)-20250404T031700Z-001/Data Collection (OpenBCI & PsychoPy)/EEG/3_9_2025_JoshIrby_OpenBCI/OpenBCISession_2025-03-09_14-39-02/BrainFlow-RAW_2025-03-09_14-39-02_0.csv\",\n",
    "    \"psychopy_csv\": \"C:/Users/cheng/OneDrive/Desktop/NeuroLingo/Data Collection (OpenBCI & PsychoPy)-20250404T031700Z-001/Data Collection (OpenBCI & PsychoPy)/PsychoPy/3_9_2025_JoshIrby_PsychoPy/6_finaltest_2025-03-09_14h42.58.498.csv\",\n",
    "    \"psychopy_log\": \"C:/Users/cheng/OneDrive/Desktop/NeuroLingo/Data Collection (OpenBCI & PsychoPy)-20250404T031700Z-001/Data Collection (OpenBCI & PsychoPy)/PsychoPy/3_9_2025_JoshIrby_PsychoPy/6_finaltest_2025-03-09_14h42.58.498.log\"\n",
    "}\n",
    "\n",
    "JoshuaWei = {\n",
    "\t\"name\": \"JoshuaWei\",\n",
    "    \"eeg\": \"C:/Users/cheng/OneDrive/Desktop/NeuroLingo/Data Collection (OpenBCI & PsychoPy)-20250404T031700Z-001/Data Collection (OpenBCI & PsychoPy)/EEG/3_13_2025_JoshuaWei_OpenBCI/OpenBCISession_2025-03-13_19-40-36/BrainFlow-RAW_2025-03-13_19-40-36_0.csv\",\n",
    "    \"psychopy_csv\": \"C:/Users/cheng/OneDrive/Desktop/NeuroLingo/Data Collection (OpenBCI & PsychoPy)-20250404T031700Z-001/Data Collection (OpenBCI & PsychoPy)/PsychoPy/3_13_2025_JoshuaWei_PsychoPy/42069_finaltest_2025-03-13_20h02.28.660.csv\",\n",
    "    \"psychopy_log\": \"C:/Users/cheng/OneDrive/Desktop/NeuroLingo/Data Collection (OpenBCI & PsychoPy)-20250404T031700Z-001/Data Collection (OpenBCI & PsychoPy)/PsychoPy/3_13_2025_JoshuaWei_PsychoPy/42069_finaltest_2025-03-13_20h02.28.660.log\"\n",
    "}\n",
    "\n",
    "Sarah = {\n",
    "\t\"name\": \"Sarah\",\n",
    "    \"eeg\": \"C:/Users/cheng/OneDrive/Desktop/NeuroLingo/Data Collection (OpenBCI & PsychoPy)-20250404T031700Z-001/Data Collection (OpenBCI & PsychoPy)/EEG/3_9_2025_Sarah_OpenBCI/OpenBCISession_2025-03-09_13-24-49/BrainFlow-RAW_2025-03-09_13-24-49_0.csv\",\n",
    "    \"psychopy_csv\": \"C:/Users/cheng/OneDrive/Desktop/NeuroLingo/Data Collection (OpenBCI & PsychoPy)-20250404T031700Z-001/Data Collection (OpenBCI & PsychoPy)/PsychoPy/3_9_2025_Sarah_PsychoPy/138512_finaltest_2025-03-09_13h31.15.766.csv\",\n",
    "    \"psychopy_log\": \"C:/Users/cheng/OneDrive/Desktop/NeuroLingo/Data Collection (OpenBCI & PsychoPy)-20250404T031700Z-001/Data Collection (OpenBCI & PsychoPy)/PsychoPy/3_9_2025_Sarah_PsychoPy/138512_finaltest_2025-03-09_13h31.15.766.log\"\n",
    "}\n",
    "\n",
    "Devin = {\n",
    "\t\"name\": \"Devin\",\n",
    "    \"eeg\": \"C:/Users/cheng/OneDrive/Desktop/NeuroLingo/Data Collection (OpenBCI & PsychoPy)-20250404T031700Z-001/Data Collection (OpenBCI & PsychoPy)/EEG/3_11_2025_Devin_OpenBCI/OpenBCISession_2025-03-11_17-07-21/BrainFlow-RAW_2025-03-11_17-07-21_1.csv\",\n",
    "    \"psychopy_csv\": \"C:/Users/cheng/OneDrive/Desktop/NeuroLingo/Data Collection (OpenBCI & PsychoPy)-20250404T031700Z-001/Data Collection (OpenBCI & PsychoPy)/PsychoPy/3_11_2025_Devin_PsychoPy/devin_finaltest_2025-03-11_17h30.44.028.csv\",\n",
    "    \"psychopy_log\": \"C:/Users/cheng/OneDrive/Desktop/NeuroLingo/Data Collection (OpenBCI & PsychoPy)-20250404T031700Z-001/Data Collection (OpenBCI & PsychoPy)/PsychoPy/3_11_2025_Devin_PsychoPy/devin_finaltest_2025-03-11_17h30.44.028.log\"\n",
    "}\n",
    "\n",
    "Afnaan = {\n",
    "\t\"name\": \"Afnaan\",\n",
    "    \"eeg\": \"C:/Users/cheng/OneDrive/Desktop/NeuroLingo/Data Collection (OpenBCI & PsychoPy)-20250404T031700Z-001/Data Collection (OpenBCI & PsychoPy)/EEG/3_13_2025_Afnaan_OpenBCI/OpenBCISession_2025-03-13_22-03-16/BrainFlow-RAW_2025-03-13_22-03-16_0.csv\",\n",
    "    \"psychopy_csv\": \"C:/Users/cheng/OneDrive/Desktop/NeuroLingo/Data Collection (OpenBCI & PsychoPy)-20250404T031700Z-001/Data Collection (OpenBCI & PsychoPy)/PsychoPy/3_13_2025_Afnaan_PsychoPy/69000_finaltest_2025-03-13_22h43.00.897.csv\",\n",
    "    \"psychopy_log\": \"C:/Users/cheng/OneDrive/Desktop/NeuroLingo/Data Collection (OpenBCI & PsychoPy)-20250404T031700Z-001/Data Collection (OpenBCI & PsychoPy)/PsychoPy/3_13_2025_Afnaan_PsychoPy/69000_finaltest_2025-03-13_22h43.00.897.log\"\n",
    "}\n",
    "\n",
    "Chengyi = {\n",
    "\t\"name\": \"Chengyi\",\n",
    "    \"eeg\": \"C:/Users/cheng/OneDrive/Desktop/NeuroLingo/Data Collection (OpenBCI & PsychoPy)-20250404T031700Z-001/Data Collection (OpenBCI & PsychoPy)/EEG/3_12_2025_Chengyi_OpenBCI/OpenBCISession_2025-03-12_17-07-49/BrainFlow-RAW_2025-03-12_17-07-49_1.csv\",\n",
    "    \"psychopy_csv\": \"C:/Users/cheng/OneDrive/Desktop/NeuroLingo/Data Collection (OpenBCI & PsychoPy)-20250404T031700Z-001/Data Collection (OpenBCI & PsychoPy)/PsychoPy/3_12_2025_Chengyi_PsychoPy/69_finaltest_2025-03-12_17h33.18.370.csv\",\n",
    "    \"psychopy_log\": \"C:/Users/cheng/OneDrive/Desktop/NeuroLingo/Data Collection (OpenBCI & PsychoPy)-20250404T031700Z-001/Data Collection (OpenBCI & PsychoPy)/PsychoPy/3_12_2025_Chengyi_PsychoPy/69_finaltest_2025-03-12_17h33.18.370.log\"\n",
    "}\n",
    "\n",
    "participants = [JoshuaIrby, JoshuaWei, Sarah, Devin, Afnaan, Chengyi]\n",
    "certainly_evoked_list = []\n",
    "not_learned_evoked_list = []\n",
    "for participant in participants:\n",
    "\tcertainly_learned_event_epochs, not_learned_event_epochs = ERP_Graph(participant[\"eeg\"], participant[\"psychopy_log\"], participant[\"psychopy_csv\"], participant[\"name\"]) \n",
    "\tcertainly_evoked_list.append(certainly_learned_event_epochs.average())\n",
    "\tnot_learned_evoked_list.append(not_learned_event_epochs.average())\n",
    "evoked_dict = {\"certainly_learned\": mne.combine_evoked(certainly_evoked_list, weights='equal'), \"not_learned\": mne.combine_evoked(not_learned_evoked_list, weights='equal')}\n",
    "mne.viz.plot_compare_evokeds(evoked_dict, picks='eeg', title='ERP Comparison')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
