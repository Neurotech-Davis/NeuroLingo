{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_data_path = \"../clean_learned_EEG/combined_learned.csv\"\n",
    "not_learned_data_path = \"../clean_not_learned_EEG/combined_not_learned.csv\"\n",
    "\n",
    "learned_data = pd.read_csv(learned_data_path, header = None)\n",
    "not_learned_data = pd.read_csv(not_learned_data_path, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original learned shape: (746, 2456)\n",
      "original not_learned shape: (141, 2456)\n",
      "new learned shape: (141, 2456)\n",
      "new not_learned shape: (141, 2456)\n"
     ]
    }
   ],
   "source": [
    "# checking how much data for each category\n",
    "print(f\"original learned shape: {learned_data.shape}\")\n",
    "print(f\"original not_learned shape: {not_learned_data.shape}\")\n",
    "\n",
    "# make them equal to remove bias\n",
    "learned_data = learned_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "not_learned_data = not_learned_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# get length \n",
    "learned_length = learned_data.shape[0]\n",
    "not_learned_length = not_learned_data.shape[0]\n",
    "\n",
    "new_learned_data = learned_data.drop(index=range(not_learned_length, learned_length))\n",
    "new_not_learned_data = not_learned_data.drop(index=range(learned_length, not_learned_length))\n",
    "\n",
    "# print results\n",
    "print(f\"new learned shape: {new_learned_data.shape}\")\n",
    "print(f\"new not_learned shape: {not_learned_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Data\n",
    "\n",
    "new_learned_data['label'] = 1\n",
    "new_not_learned_data['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine and Shuffle\n",
    "\n",
    "full_data = pd.concat([new_learned_data, new_not_learned_data], ignore_index = True)\n",
    "full_data = full_data.sample(frac = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split between X and Y Data\n",
    "#X is 42 rows (epochs) 21 Learned, 21 Not Learned\n",
    "#Y is list with length 42 of 0 (NL) and 1 (L)\n",
    "\n",
    "X = full_data.drop('label', axis = 1).values\n",
    "Y = full_data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize Features\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Data into Train and Test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5861 - loss: 0.9622 - val_accuracy: 0.5652 - val_loss: 0.7817\n",
      "Epoch 2/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6721 - loss: 0.6949 - val_accuracy: 0.5652 - val_loss: 0.8225\n",
      "Epoch 3/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6572 - loss: 0.7013 - val_accuracy: 0.5652 - val_loss: 0.8482\n",
      "Epoch 4/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6883 - loss: 0.6241 - val_accuracy: 0.5652 - val_loss: 0.7467\n",
      "Epoch 5/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7227 - loss: 0.5489 - val_accuracy: 0.6087 - val_loss: 0.7480\n",
      "Epoch 6/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7001 - loss: 0.6198 - val_accuracy: 0.6087 - val_loss: 0.7244\n",
      "Epoch 7/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7275 - loss: 0.5601 - val_accuracy: 0.6522 - val_loss: 0.7135\n",
      "Epoch 8/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7076 - loss: 0.6323 - val_accuracy: 0.6087 - val_loss: 0.6869\n",
      "Epoch 9/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7828 - loss: 0.5401 - val_accuracy: 0.6957 - val_loss: 0.6436\n",
      "Epoch 10/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8351 - loss: 0.4210 - val_accuracy: 0.6087 - val_loss: 0.6599\n",
      "Epoch 11/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7606 - loss: 0.4356 - val_accuracy: 0.6087 - val_loss: 0.6420\n",
      "Epoch 12/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7573 - loss: 0.5277 - val_accuracy: 0.6522 - val_loss: 0.6439\n",
      "Epoch 13/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8053 - loss: 0.4081 - val_accuracy: 0.6522 - val_loss: 0.6154\n",
      "Epoch 14/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8480 - loss: 0.3943 - val_accuracy: 0.6087 - val_loss: 0.6591\n",
      "Epoch 15/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8017 - loss: 0.3869 - val_accuracy: 0.6087 - val_loss: 0.6569\n",
      "Epoch 16/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7738 - loss: 0.4423 - val_accuracy: 0.6087 - val_loss: 0.6749\n",
      "Epoch 17/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8223 - loss: 0.4059 - val_accuracy: 0.6087 - val_loss: 0.6521\n",
      "Epoch 18/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8687 - loss: 0.3204 - val_accuracy: 0.6957 - val_loss: 0.6276\n",
      "Epoch 19/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8940 - loss: 0.2905 - val_accuracy: 0.6957 - val_loss: 0.6064\n",
      "Epoch 20/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8560 - loss: 0.3103 - val_accuracy: 0.6957 - val_loss: 0.6450\n",
      "Epoch 21/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8601 - loss: 0.3225 - val_accuracy: 0.6087 - val_loss: 0.6777\n",
      "Epoch 22/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8416 - loss: 0.2976 - val_accuracy: 0.6957 - val_loss: 0.6868\n",
      "Epoch 23/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8482 - loss: 0.3371 - val_accuracy: 0.6522 - val_loss: 0.7072\n",
      "Epoch 24/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8964 - loss: 0.2677 - val_accuracy: 0.6522 - val_loss: 0.7139\n",
      "Epoch 25/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8965 - loss: 0.3005 - val_accuracy: 0.5652 - val_loss: 0.7685\n",
      "Epoch 26/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8094 - loss: 0.3906 - val_accuracy: 0.5652 - val_loss: 0.8130\n",
      "Epoch 27/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8639 - loss: 0.3171 - val_accuracy: 0.6087 - val_loss: 0.8716\n",
      "Epoch 28/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8707 - loss: 0.3101 - val_accuracy: 0.6087 - val_loss: 0.8269\n",
      "Epoch 29/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.2704 - val_accuracy: 0.6087 - val_loss: 0.7384\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Accuracy: 0.543859649122807\n"
     ]
    }
   ],
   "source": [
    "#Building Neural Network Model\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),                     # Prevent overfitting\n",
    "\n",
    "    Dense(32, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),                     # Prevent overfitting\n",
    "\n",
    "    Dense(1, activation='sigmoid')   # Binary output\n",
    "])\n",
    "\n",
    "# Compile with optimizer and loss function\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Add early stopping callback\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,               # Stop after 10 epochs of no improvement\n",
    "    restore_best_weights=True # Keep the best model\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=16,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop],     # Use the early stopping\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = (y_pred > 0.5).astype(\"int32\")  # convert probabilities to 0 or 1\n",
    "\n",
    "# Print accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
